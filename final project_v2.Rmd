---
title: "final project"
output: html_document
date: "2024-03-23"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Libreries

Las librerias que vamos a usar para el trabajo son las siguientes:

```{r}
library(tidyverse)
library(dplyr)
library(magrittr)
library(scales)
library(RColorBrewer)
library(ggsci)
library(ggthemes)
library(lubridate)
library(viridis)
library(ggrepel)
library(reshape)
library(gridExtra)
library(tidyverse)
library(reshape)
library(viridis)
library(tm)
library(SnowballC)
library(wordcloud)
library(NLP)
library(reshape)
library(widyr)
library(wordcloud2)
library(tidytext)
library(janeaustenr)
library(htmlwidgets)
library(topicmodels)
library(stringr)
```

## Introduction

En este Trabajo aplicaremos diferentes técnicas de Text Mining utilizando los diferentes guiones de las películas de Harry Potter para revelar diferentes patrones y tendencias en la narrativa, los personajes y las emociones que pudieron experimentar. Mediante el procesamiento de lenguaje natural, buscaremos insights sobre la evolución de la trama y el desarrollo emocional a lo largo de la saga, proporcionando insights únicos sobre uno de los universos más emblemáticos de la literatura y el cine.

Antes de continuar, queremos avisar que este trabajo está hecho por grandes fans de la saga, por lo que lo haremos con gran cariño y pedimos perdon de antemano si nos pasamos de fans. También es necesario avaisr que puede que hagamos algun spoiler pero prometemos que serán pequeños (no relacionados con la trama). Por eso, recomendamos que para los que nos lean, se vean las películas antes, o mejor aún, leeros los libros. Nos lo agradeceréis cuando los acabéis.

## Databases

La base de datos que utilizaremos en este proyecto se ha recopilado de GitHub y está accesible directamente a través del siguiente enlace: [GitHub - HP Dataset](https://github.com/Kornflex28/hp-dataset/tree/main/datasets).

```{r}

hp1 <- read_csv("hp1.csv")
hp2 <- read_csv("hp2.csv")
hp3 <- read_csv("hp3.csv")
hp4 <- read_csv("hp4.csv")
hp5 <- read_csv("hp5.csv")
hp6 <- read_csv("hp6.csv")
hp7 <- read_csv("hp7.csv")
hp8 <- read_csv("hp8.csv")

df <- rbind(hp1,hp2,hp3,hp4,hp5,hp6,hp7,hp8)
```

## Initial Hypothesis

-   Quienes son los personajes que mas han calado en la cultura popular

## TF-IDF

### Most sentences in movies

Una de las herramientas más útiles en Text Mining es el conteo de palabras en cada texto para determinar lo relevante que puede ser cierto vocabulario o tema dentro de un corpus. Este enfoque nos permite identificar términos clave, frecuencias y patrones que emergen en el discurso, ofreciendo una ventana hacia los temas predominantes y la importancia relativa de diferentes conceptos a lo largo de la narrativa.

No obstante, el conteo también es útil para identificar quienes son los personajes principales en las diferentes novelas o en esta caso, películas. Considerando que aquellas personas que muestren un numero más alto de lineas de guion en una pelicula deberían ser los protagonistas.

Eso va a ser el primer pasoque hagamos en nuestro trabajo, identificar los protagonistas de las diferentes peliculas. Por suerte, somos grandes fans de la saga y vamos a poder comprobar los resultados de manera bastante sencilla, pero podríamos hacerlo con cualquier guión para saber su importancia.

```{r}
# Save df as a dataframe with variables 'character' and 'movie'
Char_Dial <- data.frame(table(df$character, df$movie))

# Sum lines for each character throughout all movies
Char_Dial_Sum <- Char_Dial %>%
  group_by(Var1) %>%
  summarise(Total_Freq = sum(Freq)) %>%
  ungroup()

# Select top 10 characters with the most spoken lines
Char_Dial_Top10 <- Char_Dial_Sum %>%
  arrange(desc(Total_Freq)) %>%
  slice_max(Total_Freq, n = 10)

# Create a graph for the top 10 characters with the most lines
ggplot(Char_Dial_Top10, aes(x = reorder(Var1, Total_Freq), y = Total_Freq)) +
  geom_bar(stat = "identity", width = 0.62, fill = "steelblue") +
  coord_flip() +
  labs(title = "Characters with the most sentences",
       subtitle = "Top 10 across all parts of a movie series",
       x = "Character", y = "Number of sentences") +
  theme_minimal() +
  theme(legend.position = "none")  # Remove legend because it is not relevant


```

En este gráfico podemos observar quienes son los 10 personajes más protagonistas en la saga de Harry Potter.

Como era de esperar, el personaje que más frases tiene en las peliculas es aquel que aparece en el título de las películas y es el que conocen como `El elegido`o Harry Potter, para los que no son tan fans. Seguido de Harry vienen sus mejores amigos, `Ron Weasly` y `Hermione Granger`, completando así, el`Trío de Oro`

No obstante, al revisar los resultados y como fans de la saga nos llama la atencion la aparición de un personaje en concreto `Horace Slughorn` este personaje aparece en la sexta entrega teniendo gran protagonismo solo en esta, siendo más olvidado en la ultimas dos. Además, en esta lista hay grandes olvidados como puede ser el caso de `Draco Malfoy` que a pesar de haber sido un personaje muy importante en la saga, siendo unos principales enemigos de Harry Potter, no se encuentra en el top 10. Esto peude ser un llamamiento del gran impacto que tuvo este personaje en la cultura popular, pues toda persona que haya visto las películas o leido los libros, se acuerda de este personaje, pero en cambio apenas aparece en pantalla, según los resultados obtenidos.

A continuación, vamos a dividir este análisis por películas, para observar como se reparten las frases en toda la saga. Para ello vamos guardar en el siguiente vector los nombres de mencionados personajes, con la licencia de cambiar a `Horace Slughorn` por `Draco Malfoy`.

```{r}
top_characters <- c("Harry Potter", "Ron Weasley", "Hermione Granger", "Albus Dumbledore",  "Rubeus Hagrid", "Severus Snape", "Minerva McGonagall", "Voldemort","Neville Longbottom", "Draco Malfoy")

movie_order <- tribble(~num, ~movie,
  1 , "Harry Potter and the Philosopher's Stone",
                 2, "Harry Potter and the Chamber of Secrets",
                 3, "Harry Potter and the Prisoner of Azkaban",
                 4, "Harry Potter and the Gobelt of Fire",
                 5, "Harry Potter and the Order of the Phoenix",
                 6, "Harry Potter and the Half-Blood Prince",
                 7, "Harry Potter and the Deathly Hallows Part 1",
                 8, "Harry Potter and the Deathly Hallows Part 2"
                 )

df <- df |> 
  left_join(movie_order, by = "movie")

Char_Dial <- data.frame(table(df$character, df$movie, df$num))
Char_Dial %>%
  mutate(Var3 = as.numeric(Var3)) |> 
  arrange(desc(Freq)) %>%
  filter(Var1 %in% top_characters) %>%
  ggplot(., aes(reorder(Var1, +Freq), Freq, fill = Var2)) +
  geom_bar(stat = "identity", width = 0.62)+
  scale_fill_uchicago()+
  coord_flip()+
  guides(fill = guide_legend(title.position = "top", reverse = T))+
  labs(title = "Characters with the most sentences",
       subtitle = "Top 10, by movie", fill = "Movie",
       x = "Character", y = "Number of sentences")+
  theme_minimal()+
  theme(legend.title.align = 0.5, legend.position = "right", legend.direction = "vertical") 

```

### Most used Spells

En este apartado, vamos a hablar de magia, más concretamente de hechizos. En el mundo de Harry Potter, para poder hacer magiaa, tienes que conjurar un hechizo de una manera determinada. Es por ello, que vamos a ver cuales son los hechizos más usados dentro de la saga.

Para ello, en primer lugar, vamos a guardar en un vector todos los hechizos que se mencionan en las películas. Para ver de donde hemos cogido los hechizos pincha [here](https://screenrant.com/harry-potter-spells-list-from-movies-and-books/).

```{r}
spells <- c('Accio', 'Alohomora', 'Avada Kedavra', 'Crucio', 'Expecto Patronum', 'Expelliarmus', 'Imperio',
 'Lumos', 'Obliviate', 'Petrificus Totalus', 'Reparo', 'Riddikulus', 'Sectumsempra', 'Wingardium Leviosa')

# Agregamos una columna para identificar el hechizo mencionado en cada diálogo
df$spell <- NA  # Initialize the variable with `NA`

for(spell in spells) {
  df$spell <- ifelse(grepl(spell, df$dialog, ignore.case = TRUE), spell, df$spell)
}

# Calculamos el conteo de cada hechizo
spell_counts <- df %>%
  filter(!is.na(spell)) %>% # Exclude lines without spells
  count(spell, sort = TRUE) # Count occurances for each spell and sort in order

library(viridis) # Make sure to have this package installed

# Asumiendo que 'spell_counts' ya está creado y contiene los datos de frecuencia de hechizos
ggplot(spell_counts, aes(x = reorder(spell, n), y = n, fill = spell)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = n), position = position_dodge(width = 0.9), hjust = -0.1, size = 3.5) + # Etiquetas de frecuencia
  coord_flip() +
  scale_fill_viridis(discrete = TRUE, option = "D") + # Use a color palette for discrete data 
  labs(title = 'Spells most commonly used',
       subtitle = "Frequency of mentioning spells in dialogues",
       x = 'Spells',
       y = 'Frequency') +
  theme_minimal() +
  theme(legend.title = element_blank(), # O considera eliminar la leyenda si es redundante
        axis.title.x = element_text(size = 12, face = "bold"),
        axis.title.y = element_text(size = 12, face = "bold"),
        plot.title = element_text(size = 14, face = "bold"),
        plot.subtitle = element_text(size = 10),
        legend.position = "none") # O ajusta la posición de la leyenda si prefieres mantenerla
```

Los hechizos más usados son `Expeliarmus` y `Expecto Patronum` con un total de 12 veces repartidas por las 8 películas. Pero vamos a ver como se distribuyen por película.

The most used spells are `Expeliarmus` and `Expecto Patronum` with a total of 12 times throughout all 8 movies. But let's see how they are distributed across the series. 

```{r}
Spels_df <- data.frame(table(df$character, df$movie, df$spell))

Spels_df %>%
  arrange(desc(Freq)) %>%
  filter(Var3 %in% spells) %>%
  ggplot(aes(reorder(Var3, +Freq), Freq, fill = Var2)) +
  geom_bar(stat = "identity", width = 0.62) +
  scale_fill_brewer(palette = "Set2") + # Paleta de colores "Set3" para datos categóricos
  coord_flip() +
  guides(fill = guide_legend(title.position = "top", title = "Movie Part")) +
  labs(title = "Spells most commonly used",
       subtitle = "Frequency of mentioning spells by movie",
       x = "Spells",
       y = "Number of appareances") +
  theme_minimal() +
  theme(legend.title.align = 0.5, 
        legend.position = "right", 
        legend.direction = "vertical",
        plot.title = element_text(size = 14, face = "bold"),
        plot.subtitle = element_text(size = 12),
        axis.title.x = element_text(size = 12),
        axis.title.y = element_text(size = 12),
        legend.text = element_text(size = 10)) # Ajustes de legibilidad y estética

```

```{r}
Spels_df |> 
  filter(Freq > 0) |> 
  select(Var2, Var3) |> 
  distinct() |> 
  count( Var3) |> 
  ggplot(aes(reorder(Var3, +n), n, fill = n)) +
  geom_bar(stat = "identity", width = 0.62) +
  #scale_fill_manual(values = c("peru", "gray90")) + # Paleta de colores "Set3" para datos categóricos
  coord_flip() +
  guides(fill = guide_legend(title.position = "top", title = "Movie Part")) +
  labs(title = "Riddikulus is in only one movie",
       subtitle = "Number of movie mentioning spells",
       x = "Spells",
       y = "Number of appareances") +
  theme_minimal() +
  theme(legend.title.align = 0.5, 
        legend.position = "right", 
        legend.direction = "vertical",
        plot.title = element_text(size = 14, face = "bold"),
        plot.subtitle = element_text(size = 12),
        axis.title.x = element_text(size = 12),
        axis.title.y = element_text(size = 12),
        legend.text = element_text(size = 10)) # Ajustes de legibilidad y estética
```


Una vez visto como se distribuyen los hechizos por película, otra opcion de visualizarlo es dividirlo en funcion de quien son los personajes que lo conjuran. Vayamos a ello:

```{r,  fig.width=15, fig.asp=0.65, out.width='100%', preview = TRUE}

spell_character_counts <- df %>%
  filter(spell %in% spells) %>% # Asumiendo 'spells' contiene los nombres de hechizos de interés
  count(spell, character) %>%
  arrange(spell, desc(n))

# Creando el gráfico
ggplot(spell_character_counts, aes(x = reorder(character, n), y = n, fill = character)) +
  geom_bar(stat = "identity") +
  facet_wrap(~ spell, scales = "free_y") + # Usa facetas para cada hechizo con escalas libres en y
  coord_flip() + # Barras horizontales
  scale_fill_viridis_d(begin = 0.2, end = 0.8, direction = -1, option = "C") + # Paleta de colores
  labs(title = "Character Spell Usage",
       x = "Character",
       y = "Frequency of Spell Usage") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        strip.text.x = element_text(face = "bold"),
        legend.position = "none") # Mejora de legibilidad y estética
```

Aquí podemos observar la distribución de los diferentes hechizos conjurados por los diferentes personajes. Podemos observar como en la mayoria predominan o `Harry Potter` o `Hermione Granger`. Lo cual sirve de gran indicador de la relevancia de estos personajes, así como, tambien muestra quienes son otros personajes influyentes en la trama.

En este punto, ya hemos averiguado cuales son los hechizos que más usan y los personajes que más hablan. El siguiente paso consistirá en observar cuales son las palabras que mas se repiten y calcular su frecuencia.

### Most used Words

El primer paso, es comprobar cual es la película que más guión tiene o más larga. Es decir, asimiremos que las peliculas que tienen mayor cantidad de dialogos, son aquellas que nos ofrecen una mayor cantidad de minutos en la gran pantalla.

```{r}
library(dplyr)

total_dialogs <- df %>%
  group_by(movie) %>%
  summarize(total_dialogs = n())  # Cuenta el número de filas por grupo, lo que equivale a contar diálogos

total_dialogs

```

Vamos a representarlo en un grafico.

```{r}

# Asumiendo que total_dialogs ya contiene los datos necesarios
ggplot(total_dialogs, aes(x = reorder(movie, -total_dialogs), y = total_dialogs, fill = movie)) +
  geom_bar(stat = "identity") +
  coord_flip() + # Barras horizontales
  labs(title = "Total Dialogs by Harry Potter Movie",
       x = "Movie",
       y = "Total Dialogs") +
  theme_minimal() +
  theme(legend.position = "none") # No necesitamos leyenda ya que los nombres de las películas están en el eje x

```

Observando los resultados y comparandolo con la duracion de las películas, podemos observar que no coincide, es decir, la pelicula que tiene más dialogos es `Harry Potter and the Order of the Phoenix`, siendo la segunda película más corta de la saga. La información sobre la duración de las películas es la siguiente, aunque puedes encontrar más información sobre ello, en el siguiente [link](https://www.pottertalk.net/harry-potter-movie-lengths/).

-   Sorcerer’s Stone = 152 minutes = 2 hours 32 minutes

-   Chamber of Secrets = 161 minutes = 2 hours 41 minutes

-   Prisoner of Azkaban = 142 minutes = 2 hours 22 minutes

-    Goblet of Fire = 157 minutes = 2 hours 37 minutes

-    Order of the Phoenix = 139 minutes = 2 hours 18 minutes

-   Half Blood Prince = 153 minutes = 2 hours 33 minutes

-    Deathly Hallows pt 1 = 146 minutes = 2 hours 26 minutes

-   Deathly Hallows pt 2 = 130 minutes = 2 hours 10 minutes

Parece que no hay tanta relacion entre la cantidad de dialogos y el numero de minutos en la película. Hagamos lo mismo, pero en lugar de dialogos por palabras.

```{r}
#we obtain the text from the library
words <- df %>%
  unnest_tokens(word, dialog) %>%
  count(movie, word, sort = TRUE)

movie_words <-  df %>%
  # we tokenize as usual (as an exception we won't be filtering stopwords now)
  unnest_tokens(word, dialog) %>%
  count(movie, word, sort = TRUE) |> 
   group_by(movie) %>% 
  summarize(total_words = sum(n))
movie_words

ggplot(movie_words, aes(x = reorder(movie, -total_words), y = total_words, fill = movie)) +
  geom_bar(stat = "identity") +
  coord_flip() + # Barras horizontales
  labs(title = "Total Words by Harry Potter Movie",
       x = "Movie",
       y = "Total Words") +
  theme_minimal() +
  theme(legend.position = "none")

```
Nuevamente, vemos que aunque tenga una mayor relacion el numero de palabras con la duracion de la película, esta no coincide, por lo que podemos descartar la hipotesis de que a mayor dialogo, mayor es la duracion de la pelicula.

Una vez hemos comprobado esto, el siguiente paso que haremos sera observar el term frecuency de cada palabra, para observar cuales son las palabras más representativas de cada película.  Esta se calcula como el numero de veces que la palabra se repite en en la película dividido por el numero de palabras totales que hay en toda la pelicula. 

```{r}
movie_words <- words %>%
 left_join(movie_words, by = "movie") |> 
  #we add a column for term_frequency in each novel
  mutate(term_frequency = n/total_words)
movie_words

ggplot(movie_words, aes(x = term_frequency)) +
  geom_histogram(binwidth = 0.0001, fill = "#0073C2FF", color = "black") +
  xlim(NA, 0.009) + # Límites en el eje x para enfocar hasta 0.01
  scale_y_continuous(breaks = seq(0, 7000, by = 500)) + # Ajusta los breaks del eje y
  labs(title = "Distribution of Term Frequency Across All Movies",
       x = "Term Frequency (as a percentage of total words)",
       y = "Count") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))



```
Este gráfico es un histograma que muestra la distribución de la frecuencia de términos en diálogos a lo largo de todas las películas de Harry Potter. Cada barra representa la cantidad de términos (eje y) que ocurren con cierta frecuencia (eje x) dentro del conjunto total de palabras de las películas. Se puede observar que hay un gran numero de palabras con baja frecuencia, lo que sugiere que hay una gran cantidad de palabras que no se repiten. 

Ahora vamos a observar una distrbucion de frecuencia pero por película, observando que pelicula es mas rica en vocabulario. 

```{r}
ggplot(movie_words, aes(x = term_frequency, fill = movie)) +
  geom_histogram(bins = 30, position = "identity") + # Eliminamos la transparencia con alpha
  scale_x_continuous(limits = c(NA, 0.0009), labels = scales::percent_format(accuracy = 0.01)) +
  scale_fill_manual(values = c("Harry Potter and the Chamber of Secrets" = "#1f77b4",
                                "Harry Potter and the Deathly Hallows Part 1" = "#ff7f0e",
                                "Harry Potter and the Deathly Hallows Part 2" = "#2ca02c",
                                "Harry Potter and the Goblet of Fire" = "#d62728",
                                "Harry Potter and the Half-Blood Prince" = "#9467bd",
                                "Harry Potter and the Order of the Phoenix" = "#8c564b",
                                "Harry Potter and the Philosopher's Stone" = "#e377c2",
                                "Harry Potter and the Prisoner of Azkaban" = "#7f7f7f")) + # Añade más colores según sea necesario
  labs(title = "Distribution of Term Frequency Across Movies",
       x = "Term Frequency (as a percentage of total words)",
       y = "Count") +
  theme_minimal() +
  theme(legend.position = "right", legend.title = element_blank())
```
Podemos observar que la pelicula más rica en vocabulario es `Harry Potter and the Half-Blood Prince`. No obstante no se observa con claridad la distribucion de las diferentes películas. 

```{r,  fig.width=15, fig.asp=0.65, out.width='100%', preview = TRUE}
# Vizualization
ggplot(movie_words, aes(x = term_frequency, fill = movie)) +
  geom_histogram(binwidth = 0.0001, color = "white") + 
  scale_x_continuous(limits = c(NA, 0.003), labels = scales::percent_format(accuracy = 0.0001)) + 
  facet_wrap(~ movie, ncol = 2, scales = "free_y") + 
  scale_fill_brewer(palette = "Set3") + 
  labs(title = "Term Frequency Distribution by Movie",
       x = "Term Frequency",
       y = "Count") +
  theme_light() + # Aplicamos un tema claro
  theme(legend.position = "bottom", 
        axis.text.x = element_text(angle = 45, hjust = 1), 
        strip.background = element_rect(fill = "lightblue"), 
        strip.text.x = element_text(size = 8, color = "navy"))
```

En general podemos observar que todas las películas presentan la misma dsitribucion. 

### TF-IDF

El siguiente paso en nuestro análisis es utilizar la técnica de frecuencia de término-frecuencia inversa de documento (tf-idf) para resaltar palabras que son distintivas en cada película de la serie de Harry Potter. Tf-idf es útil porque nos ayuda a identificar no solo las palabras más frecuentes, sino también las que son especialmente significativas en un documento determinado en relación con una colección de documentos. Esto nos permite ver más allá de la mera frecuencia y considerar la relevancia de un término, dándonos una visión más matizada de cómo se utiliza el lenguaje en las diferentes películas.

Al calcular el tf-idf de cada término en el contexto de cada película, podemos filtrar y visualizar las 20 palabras más caracterizadoras por película, lo que nos da una lista de términos distintivos que definen o son emblemáticos de cada una.

```{r,  fig.width=15, fig.asp=0.65, out.width='100%', preview = TRUE}
#we create a new variable with the analysis
movie_tf_idf <- movie_words %>%
  bind_tf_idf(word, movie, n) |> 
  select(-total_words) %>%
  #we arrange by tf-idf in descending order
  arrange(desc(tf_idf))

# Vizualization
movie_tf_idf %>%
  group_by(movie) %>%
  slice_max(tf_idf, n = 20) %>%
  ungroup() %>%
  ggplot(aes(tf_idf, fct_reorder(word, tf_idf), fill = movie)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ movie, ncol = 2, scales = "free") +
  scale_fill_brewer(palette = "Set2") + 
  labs(x = "TF-IDF", y = "Words") + 
  theme_minimal() + 
  theme(axis.text.y = element_text(angle = 0), 
        strip.background = element_rect(fill = "lightblue"), 
        strip.text.x = element_text(size = 10, color = "navy"))
```

Este análisis es bastante representativo y es de gran ayuda para identificar factores muy relevantes en la trama. Además, al pararnos a observar los resultados estos son bastantes fieles con la realidad, debido a que nosotros como fans podemos afirmar que en la mayoria de casos, las palabras que presentan un mayor tf-idf son muy importantes en la película. 

Por ejemplo, en `Harry Potter and the Deathly Hallows Part 1` la palabra más distintiva es Dobby, este personaje, sin entrar en profundidad para no hacer spoiler, tiene una escena de las más importantes y conmomedoras de toda la saga en esta película. Por otro lado, si nos fijamos en la quinta entrega de la saga ( `Harry Potter and the Order of the Phoenix`), la palabra más distintiva es `prohesy` lo cual tiene sentido debido a que toda la película gira en torno a una profecia muy imporntante en la historia. Así como, en la tercera entrega `Harry Potter and the Prisoner of Azkaban` la palabra mas importante es `Pettigrew` y `dementos`, siendo ambas palabras bastante relevantes en esta película. Si la persona que lee esto es fan, estará de acuerdo con los resultados obtenidos. 

Finalmente, al principio del análisis nos sorprendía las secuencias de dialogo que tenia `Horace Slughorn`, pues solo aparece en 3 de las 8 películas, pero al parecer este personaje es muy disntintivo en la sexta, siendo su nombre y apellido las palabras más importantes de toda la película. 














# Sentiment analysis
```{r}
Bing <- get_sentiments("bing")

Bing$sentiment <- first(Bing$sentiment)

df %>%
  unnest_tokens(output = word, input = dialog, token = "ngrams", n = 2) %>%
  filter(is.na(word)==F) %>%
  separate(word, c("word1", "word2"), sep = " ") %>% 
  filter(!word1 %in% c("on", "ha", "in", "the", "be", "are", "i", "you", "is", "to", "a", "has", "of", "it", "he", "was", "it's")) %>%
  filter(!word2 %in% c("on", "in", "ha", "the", "be", "are", "i", "you", "is", "to", "a", "has", "of", "it", "he", "was", "it's")) %>% 
  unite(word,word1, word2, sep = " ") %>% 
  count(word, sort = T) %>% 
  slice(1:15) %>%
ggplot(., aes(reorder(word, +n), n))+
  geom_bar(stat = "identity", width = 0.65, fill = "#a1d76a", alpha = 0.85)+
  coord_flip()+
  labs(title = "Most popular bigrams in the movies",
       subtitle = "Top 15",
       x = "Bigram content", y = "Frequency")+
  theme_minimal()

df %>%
  unnest_tokens(output = word, input = dialog, token = "ngrams", n = 3) %>%
  filter(is.na(word)==F) %>%
  separate(word, c("word1", "word2", "word3"), sep = " ") %>% 
  filter(!word1 %in% c("on", "ha", "in", "the", "be", "are", "i", "you", "is", "to", "a", "has", "of", "it", "he", "was", "it's", "we")) %>%
  filter(!word2 %in% c("you", "ha", "we", "the")) %>% 
  filter(!word3 %in% c("on", "in","ha", "the", "be", "are", "i", "you", "is", "to", "a", "has", "of", "it", "he", "was", "it's", "we")) %>% 
  unite(word,word1, word2, word3, sep = " ") %>% 
  count(word, sort = T) %>% 
  slice(1:15) %>%
ggplot(., aes(reorder(word, +n), n))+
  geom_bar(stat = "identity", width = 0.62, fill = "#a1d76a", alpha = 0.85)+
  coord_flip()+
  labs(title = "Most popular trigrams in the movies",
       subtitle = "Top 15",
       x = "Trigram content", y = "Frequency")+
  theme_minimal()
```

```{r}
Sentiment <- df %>%
  unnest_tokens(output = word, input = dialog) %>%
  left_join(Bing, "word") %>%
  filter(is.na(sentiment)==F)

Sentiment %>% 
  group_by(word, sentiment) %>%
  summarise(count = n(), .groups = 'drop') %>%
  arrange(desc(count)) %>%
  slice(1:20) %>%
ggplot(., aes(reorder(word, +count), count, fill = sentiment))+
  geom_bar(stat = "identity", width = 0.62, alpha = 0.9)+
  scale_fill_brewer(palette = "Set1")+
  coord_flip()+
  labs(title = "Most popular words with assigned sentiment",
       subtitle = "Top 20",
       x = "Word", y = "Frequency", fill = "Sentiment")+
  guides(fill = guide_legend(reverse = T))+
  theme_minimal()+
  theme(legend.title.align = 0.5, legend.position = "right", legend.direction = "vertical")
```

```{r}
Sentiment %>% 
  group_by(movie, sentiment) %>%
  summarise(count = n(), .groups = 'drop') %>%
ggplot(., aes(movie, count, fill = sentiment))+
  geom_bar(stat = "identity", position = "fill", width = 0.7, alpha = 0.9)+
  scale_fill_brewer(palette = "Set1")+
  scale_y_continuous(labels = scales::percent)+
  coord_flip()+
  labs(title = "Share of words with positive and negative sentiment",
       subtitle = "by part of a movie series", fill = "Sentiment",
       x = "Part of a movie series", y = "Ratio")+
  guides(fill = guide_legend(reverse = T))+
  theme_minimal()+
  theme(legend.title.align = 0.5, legend.position = "right", legend.direction = "vertical")
```

```{r}
Sentiment %>% 
  filter(character %in% c("Harry Potter", "Ron Weasley", "Hermione Granger", "Rubeus Hagrid", "Albus Dumbledore", "Remus Lupin", "Minerva McGonagall", "Draco Malfoy", "Severus Snape", "Lucius Malfoy", "Voldemort", "Tom Riddle", "Sirius Black", "Neville Longbottom"))  %>%
  group_by(character, sentiment) %>%
  summarise(count = n(), .groups = 'drop') %>%
ggplot(., aes(character, count, fill = sentiment))+
  geom_bar(stat = "identity", position = "fill", width = 0.57, alpha = 0.9)+
  scale_x_discrete(limits = c("Harry Potter", "Ron Weasley", "Hermione Granger", "Rubeus Hagrid", "Albus Dumbledore", "Remus Lupin", "Minerva McGonagall", "Draco Malfoy", "Severus Snape", "Lucius Malfoy", "Voldemort", "Tom Riddle", "Sirius Black", "Neville Longbottom"))+
  scale_fill_brewer(palette = "Set1")+
  scale_y_continuous(labels = scales::percent)+
  coord_flip()+
  geom_hline(yintercept = 0.5)+ 
  labs(title = "Share of words with positive and negative sentiment",
       subtitle = "by character (top 15 characters with the most sentences)", fill = "Sentiment",
       x = "Character", y = "Ratio")+
  guides(fill = guide_legend(reverse = T))+
  theme_minimal()+
  theme(legend.title.align = 0.5, legend.position = "right", legend.direction = "vertical")
```

## TOPIC MODELLING

En una saga con múltiples películas, como Harry Potter, donde los personajes, los argumentos y los motivos evolucionan a lo largo del tiempo, el modelado de temas podría identificar patrones y cambios temáticos en la narrativa. Esto podría revelar cómo ciertos temas son introducidos, cómo se desarrollan a lo largo de las películas y qué películas se centran más en ciertos aspectos de la historia o los personajes. La ventaja es que, en lugar de mirar palabras individuales como en el análisis TF-IDF, estaríamos examinando patrones de palabras que representan temas, lo que podría proporcionar una comprensión más profunda del contenido y la estructura de las narrativas de la serie.

En primer lugar vamos a preparar la dataset con la que vamos a trabajar a lo largo del apartado.  Para ello, utilizaremos los capítulos que hacen referencia a the chapter of the movie according to the script

```{r}
library(stringr)

# divide into documents, each representing one chapter
by_chapter <- df %>%
  unite(document, movie, chapter)

# tokenize
by_chapter_word <- by_chapter %>%
  unnest_tokens(word, dialog)

# find document-word counts
word_counts <- by_chapter_word %>%
  anti_join(stop_words) %>%
  count(document, word, sort = TRUE)

word_counts
```
We have now a tidy dataframe with document, word, and how many times the word appears in the document. El siguiente paso es aplicar el LDA a los capítulos.

### LDA

En primer lugar, vamos a observar el grado de sparsity.

```{r}
chapters_dtm <- word_counts %>%
  cast_dtm(document, word, n)

chapters_dtm
```
Los resultados muestran un 99% de Sparsity en todas las películas, lo que da a entender que el vocabulario que se emplea es muy rico, lo cual es de esperar, debido que al tratarse de guiones de películas, quizá es menos frecuente que el vocabulario tienda a repetirse, como quizá podría ocurrir más en los libros.El alto grado de sparsity is a good sign that the topic modelling will be successful. Por lo que podemos aplicar LDA sin problemas. 

```{r}
library(topicmodels)
# 4 topics are applied
chapters_lda <- LDA(chapters_dtm, k = 4, control = list(seed = 1234)) 
chapters_lda
```
No obstante, para poder continuar con el análisis, es necesario poder trasformar el formato a tidy. 

```{r}
chapter_topics <- tidy(chapters_lda)
chapter_topics
```
Al analizar los valores de beta en nuestro modelo de temas, es evidente que algunas palabras tienen asociaciones fuertes con temas particulares, lo que nos da pistas sobre su relevancia en el contexto de la historia. Sigamos adelante y visualicemos las cinco palabras principales de cada tema, lo que nos ofrecerá una visión clara y tangible de los motivos recurrentes a lo largo de la serie.

```{r}
library(forcats)
top_terms <- chapter_topics %>%
  group_by(topic) %>%
  slice_max(beta, n = 5) %>%
  ungroup() %>%
  arrange(topic, -beta) %>%
  mutate(term = reorder_within(term, beta, topic))  # Reordena los términos dentro de cada tema para la visualización

# Creando el gráfico
ggplot(top_terms, aes(x = beta, y = term, fill = as.factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  scale_y_reordered() +  # Asegura que los términos estén correctamente ordenados dentro de las facetas
  labs(x = "Beta Value", y = "Top Terms") +
  theme_minimal() +
  theme(axis.title.y = element_blank(),  # Elimina el título del eje y para más limpieza
        strip.background = element_rect(fill = "lightblue"),  # Personaliza el fondo de las etiquetas de faceta
        strip.text = element_text(size = 12, color = "navy"))  # Personaliza el texto de las etiquetas de faceta
```
Echando un vistazo, parece que `harry` es un término estrella, encabezando los temas 3,4,5,6,7,8 y en el 2 siendo `Potter`. Esto no es sorprendente, ya que estamos hablando de Harry Potter. En el tema 1, palabras como `sir`,`dumbledore` y `professor`, acompañan a `harry`. 

El tema 2 muestra una variedad diferente, con `ron` y `hermione` cerca de la cima, lo que sugiere que este tema podría tratar sobre los amigos y compañeros de Harry. Por otro lado, el tema 3 destaca `hagrid` y `hermione`junto a `harry`, quizás señalando momentos clave donde estos personajes interactúan o juegan roles significativos.

Finalmente, el tema 4, aparte de `harry`, destaca `dobby` y `time`. `Dobby` podría estar asociado a momentos emocionales y significativos de la saga, mientras que "time" podría estar relacionado con eventos críticos en la trama o incluso con el giratiempo de "El Prisionero de Azkaban".

### Each chapter to its book
Una vez, hemos hemos identificado esas palabras clave que definen con cada tema, el siguiente paso es intentar reconstruir el rompecabezas de los capítulos y asignar cada uno a su libro original. Para hacerlo, vamos a utilizar gamma, que nos dice la probabilidad de que un capítulo contenga ciertos temas. Piensa en gamma como la afinidad que tiene un capítulo por los temas que hemos identificado, algo así como el Sombrero Seleccionador decidiendo a qué casa de Hogwarts perteneces (si el que está leyendo esto no ha visto una película o ha leido los libros de Harry Potter, se ha perdido una referencia muy buena de explicar el `gamma`) . Con esta información, podemos predecir a qué libro podría pertenecer cada capítulo basándonos en sus temas dominantes.

```{r}
chapters_gamma <- tidy(chapters_lda, matrix = "gamma")
chapters_gamma
```

Al final, cada capítulo tendrá una serie de probabilidades asociadas a los temas, y, por ende, una sugerencia de a qué libro pertenece. Este paso es crucial porque nos permite ver cómo se agrupan los capítulos y validar nuestra comprensión temática de los libros. Si lo hacemos bien, ¡podremos ver cómo las piezas del rompecabezas se unen perfectamente!

```{r}
chapters_gamma <- chapters_gamma %>%
  separate(document, c("title", "chapter"), sep = "_", convert = TRUE)

chapters_gamma
```
And now, let's make a plot:

```{r,  fig.width=15, fig.asp=0.65, out.width='100%', preview = TRUE}
# reorder titles in order of topic 1, topic 2, etc before plotting
chapters_gamma %>%
  mutate(title = fct_reorder(title, gamma, .fun = sum)) %>%  # Reordena los títulos sumando las gammas
  ggplot(aes(x = factor(topic), y = gamma, fill = factor(topic))) +  # Usa el tema como color
  geom_boxplot() +
  facet_wrap(~ title, scales = "free_y") +  # Facetas por título con escalas libres en y
  labs(x = "Topic", y = expression(Gamma)) +
  theme_minimal() +  # Tema minimalista para limpiar el gráfico
  theme(legend.position = "none",  # Removemos la leyenda para evitar redundancia
        axis.title.x = element_blank(),  # Removemos el título del eje x para una apariencia más limpia
        axis.text.x = element_text(angle = 45, hjust = 1))
```

Podemos observar cómo algunos libros muestran una preferencia clara por ciertos temas, indicada por la altura de las cajas en cada tema. Por ejemplo, `Harry Potter and the Half-Blood Prince` tiene una caja muy alta en el tema representado en rojo, lo que podría indicar que este tema es especialmente prominente en ese libro. En contraste, `Harry Potter and the Chamber of Secrets` muestra una distribución más uniforme entre dos temas, con las cajas más altas en verde y azul, es decir, lo que representaria al topic 2 y 3

La dispersión de los puntos fuera de las cajas, es decir, los outliers, podría señalar capítulos que son excepcionalmente diferentes en su contenido temático en comparación con otros capítulos dentro de su mismo libro. Por ejemplo, hay algunos capítulos en "Harry Potter and the Order of the Phoenix" que parecen ser únicos en su perfil temático, dada la dispersión de los puntos.

Let's investigate further.

First, we should have a look at the topic that has been most associated with each chapter of the book.

```{r}
chapter_classifications <- chapters_gamma %>%
  group_by(title, chapter) %>%
  #we use slice max to order by gamma
  slice_max(gamma) %>%
  ungroup()

chapter_classifications
```
Parece que la mayoría de los capítulos de "La Cámara Secreta" tienen una vinculación casi total (valores de gamma muy cercanos a 1) con los temas 2 y 3. Por ejemplo, los capítulos `About the Chamber`, `Aragog`, y `Cornelius Fudge` están firmemente ligados al tema 3. 

Algunos capítulos, como `Backfire` y `Car rescue`, están asociados casi completamente con el tema 2, lo que podría representar otra faceta central de la narrativa de este libro, tal vez más orientada hacia la acción y la aventura.

Sin embargo, hay capítulos como `Dobby's reward` y `Dobby's warning` que se desvían de esta tendencia, con una relación más fuerte con el tema 4, que puede estar reflejando aspectos más relacionados con el desarrollo del personaje o elementos de la trama que no están tan centrados en el misterio principal de la cámara.

Finalmente, para concluir nuestro análisis mágico, vamos a desvelar aquellos capítulos que, al parecer, han dado un giro inesperado en la trama y se han alineado con temas diferentes al hilo principal de su libro. Imagínalo como el Sombrero Seleccionador teniendo un día peculiar y asignando estudiantes a casas inesperadas (otra referencia muy buena que si eres fan seguro que has disfrutado y si no tienes ni idea de lo que hablo, pido perdon :))

First, we create a dataframe just with two columns: the book and its consensus topic.

```{r}
book_topics <- chapter_classifications %>%
  count(title, topic) %>%
  group_by(title) %>%
  slice_max(n, n = 1) %>% 
  ungroup() %>%
  transmute(consensus = title, topic)

book_topics
```
Second, we check with an inner join if any chapter is assigned to a topic different from the consensus.

```{r}
chapter_classifications %>%
  inner_join(book_topics, by = "topic") %>%
  filter(title != consensus)
```
La mayoría de los capítulos se asocian consistentemente con el tema 3, lo que sugiere que este tema captura elementos clave que son centrales en este libro particular. Es posible que el tema 3 encapsule el misterio y el suspense de la Cámara de los Secretos.

Sin embargo, también hay capítulos asociados con otros temas, como "Backfire" y "Car rescue" con el tema 2, y "Chamber of Secrets" con el tema 1, lo que nos dice que hay diversidad temática en el libro. Particularmente interesante es "Dobby's reward" y "Dobby's warning", que se desmarcan con una asociación al tema 4; esto puede indicar una subtrama o un enfoque en aspectos del desarrollo del personaje, especialmente en lo que respecta a Dobby.

